# VoltStream âš¡

> **Real-time Electric Vehicle Fleet Monitoring System**

High-performance vehicle telemetry ingestion and monitoring system demonstrating production-grade microservices architecture.

---

## ðŸŒ Live Demo

**Production Dashboard:** [voltstream.vercel.app](https://voltstream.vercel.app)  
> âš ï¸ **Note:** Live demo runs in **simulation mode** with realistic SF Bay Area vehicle data for zero-cost deployment
---

## ðŸŽ¯ Two Deployment Modes

This project is designed to run in two configurations:

### ðŸ“± Production (Vercel - Demo Mode)
**What you see on the live demo:**
- Next.js dashboard with realistic simulated data
- 50 vehicles in SF Bay Area
- Real-time charts, maps, and alerts
- **Data Source:** Simulated (see `dashboard-ui/lib/demo-data.ts`)
- **Cost:** $0/month
- **Purpose:** Portfolio showcase, recruiters, sharing

### ðŸ’» Local (Full Stack - Real Backend)
**What runs on your machine:**
- Complete microservices architecture
- Apache Kafka + InfluxDB + gRPC
- 1000 vehicles at 10Hz (10,000 events/sec)
- **Data Source:** Real Kafka streams from simulator
- **Cost:** $0 (runs locally)
- **Purpose:** Development, testing, demonstrating full capabilities

> **Why this approach?** Running Kafka + InfluxDB + microservices 24/7 on cloud platforms costs $20-50/month. Demo mode provides an identical user experience at zero cost while maintaining the complete production codebase for local development.

## Overview

VoltStream processes 10,000+ telemetry events per second from 1,000 simulated vehicles, demonstrating a production-ready microservices architecture with real-time visualization. Built with Go, gRPC, Apache Kafka, InfluxDB, and Next.js.

## Features

- **High Throughput**: 10k+ events/sec with sub-millisecond gRPC ingestion
- **Real-time Dashboard**: Live map tracking 1000 vehicles with instant updates
- **Anomaly Detection**: Battery overheat and tire pressure monitoring with state tracking
- **Memory Efficient**: Automatic cleanup prevents memory leaks in long-running operations
- **Scalable**: Horizontal scaling via Kafka consumer groups
- **Observable**: Prometheus metrics on gRPC server

## Architecture

```mermaid
graph TB
    subgraph "Data Generation"
        SIM[Fleet Simulator<br/>1000 vehicles @ 10Hz<br/>Go + gRPC Client]
    end

    subgraph "Ingestion Layer"
        GRPC[gRPC Server<br/>:50051<br/>Protobuf Streaming]
        METRICS[Prometheus Metrics<br/>:2112/metrics]
        GRPC --> METRICS
    end

    subgraph "Message Broker"
        KAFKA[Apache Kafka<br/>:19092<br/>Sarama v1.46.3]
        TOPIC1[Topic: telemetry-raw<br/>10k events/sec]
        TOPIC2[Topic: telemetry-alerts<br/>State-based anomalies]
        KAFKA --> TOPIC1
        KAFKA --> TOPIC2
    end

    subgraph "Processing Workers"
        WORKER[Storage Worker<br/>Kafka Consumer<br/>Batch Writes]
        ALERT[Alert Worker<br/>Kafka Consumer<br/>Anomaly Detection]
    end

    subgraph "Storage Layer"
        INFLUX[InfluxDB 2.7<br/>:18086<br/>Time-Series Database]
        INFLUX_BUCKET[Bucket: telemetry<br/>Org: voltstream]
        INFLUX --> INFLUX_BUCKET
    end

    subgraph "Visualization Layer"
        DASH_API[Dashboard API<br/>Next.js Route Handlers<br/>:3000/api/stream]
        DASH_UI[Next.js Dashboard<br/>React + Leaflet Maps<br/>Server-Sent Events]
        DASH_API --> DASH_UI
    end

    subgraph "Infrastructure"
        ZK[Zookeeper<br/>:2181]
        DOCKER[Docker Compose<br/>Local Dev Infrastructure]
        ZK -.-> KAFKA
        DOCKER -.-> ZK
        DOCKER -.-> KAFKA
        DOCKER -.-> INFLUX
    end

    %% Data Flow
    SIM -->|gRPC Bidirectional<br/>Stream| GRPC
    GRPC -->|Async Producer<br/>Protobuf| KAFKA
    TOPIC1 -->|Consumer Group<br/>Partition 0| WORKER
    TOPIC1 -->|Consumer Group<br/>All Partitions| ALERT
    WORKER -->|Async WriteAPI<br/>Batch 5000| INFLUX
    ALERT -->|Battery > 58Â°C<br/>Pressure < 30.5 PSI| TOPIC2
    TOPIC1 -->|Singleton Consumer<br/>nextjs-dashboard-v6| DASH_API
    TOPIC2 -->|Alert Consumer| DASH_API

    %% Styling
    classDef ingestion fill:#3b82f6,stroke:#1e40af,color:#fff
    classDef storage fill:#10b981,stroke:#059669,color:#fff
    classDef processing fill:#f59e0b,stroke:#d97706,color:#fff
    classDef viz fill:#8b5cf6,stroke:#6d28d9,color:#fff
    classDef infra fill:#6b7280,stroke:#4b5563,color:#fff

    class SIM,GRPC,METRICS ingestion
    class INFLUX,INFLUX_BUCKET storage
    class WORKER,ALERT processing
    class DASH_API,DASH_UI viz
    class KAFKA,TOPIC1,TOPIC2,ZK,DOCKER infra
```

**Key Components:**

- **Fleet Simulator**: Generates telemetry from 1000 vehicles, each sending data at 10Hz (4 data points per batch: lat, lon, speed, temp)
- **gRPC Server**: Receives bidirectional streams, forwards to Kafka with Prometheus metrics
- **Kafka**: Message broker with 2 topics, handles 10k+ events/sec with Snappy compression
- **Storage Worker**: Consumes telemetry-raw, batch writes to InfluxDB (5000 points/batch)
- **Alert Worker**: Monitors telemetry for anomalies, publishes state transitions to telemetry-alerts
- **Dashboard API**: SSE endpoint with singleton Kafka consumer, 5s vehicle TTL, 2s cleanup
- **Next.js UI**: Real-time map + charts, handles 1000 concurrent vehicle markers

## Tech Stack

**Backend**: Go 1.21+, gRPC, Protocol Buffers  
**Messaging**: Apache Kafka (Sarama v1.46.3)  
**Storage**: InfluxDB 2.7 (time-series)  
**Frontend**: Next.js 16, React 19, Leaflet maps, Server-Sent Events  
**Infrastructure**: Docker Compose

## Quick Start

### Local Development

1. **Start infrastructure**:
```bash
docker-compose up -d
```

2. **Build services**:
```bash
go build -o bin/server ./cmd/server
go build -o bin/worker ./cmd/worker
go build -o bin/alert-worker ./cmd/alert-worker
go build -o bin/simulator ./cmd/simulator
```

3. **Run services** (4 separate terminals):
```bash
# Terminal 1: gRPC Server
KAFKA_BROKER=localhost:19092 ./bin/server

# Terminal 2: Storage Worker
KAFKA_BROKER=localhost:19092 INFLUXDB_URL=http://localhost:18086 ./bin/worker

# Terminal 3: Alert Worker
KAFKA_BROKER=localhost:19092 ./bin/alert-worker

# Terminal 4: Simulator
./bin/simulator
```

4. **Run dashboard**:
```bash
cd dashboard-ui
npm install
npm run dev
```

Access dashboard at http://localhost:3000

## Production Deployment

Deploy the dashboard with demo mode to Vercel (free, instant):

```bash
cd dashboard-ui
npm install -g vercel
vercel --prod
```

The dashboard will be live at `your-project.vercel.app` with realistic simulated vehicle data.

**What's deployed:**
- Next.js dashboard with Server-Sent Events
- 50 simulated vehicles with realistic movement
- Live charts, alerts, and geospatial tracking
- Professional UI indistinguishable from production backend

**For recruiters/demos:**
1. Share the live Vercel URL
2. Optionally run full stack locally to show capabilities
3. Point to this GitHub repo for architecture review

---

For detailed production setup with Docker:

```bash
docker-compose -f docker-compose.prod.yml up -d
```

## Configuration

### Environment Variables

Copy example files and customize:
```bash
cp .env.example .env
cp dashboard-ui/.env.local.example dashboard-ui/.env.local
```

Key variables:
- `KAFKA_BROKER`: Kafka broker address (default: localhost:19092)
- `INFLUXDB_URL`: InfluxDB URL (default: http://localhost:18086)
- `INFLUXDB_TOKEN`: InfluxDB authentication token
- `NUM_VEHICLES`: Fleet size (default: 1000)
- `SEND_FREQUENCY_HZ`: Telemetry frequency (default: 10Hz)

See `.env.example` for complete list.

## Project Structure

```
voltstream/
â”œâ”€â”€ cmd/                    # Service entry points
â”‚   â”œâ”€â”€ server/            # gRPC ingestion server
â”‚   â”œâ”€â”€ worker/            # InfluxDB storage worker
â”‚   â”œâ”€â”€ alert-worker/      # Anomaly detection worker
â”‚   â””â”€â”€ simulator/         # Fleet simulator
â”œâ”€â”€ internal/              # Shared packages
â”‚   â”œâ”€â”€ config/           # Configuration and constants
â”‚   â”œâ”€â”€ grpc/             # gRPC server implementation
â”‚   â”œâ”€â”€ kafka/            # Kafka producer wrapper
â”‚   â””â”€â”€ storage/          # InfluxDB client
â”œâ”€â”€ proto/                # Protobuf definitions
â”œâ”€â”€ dashboard-ui/         # Next.js dashboard
â”‚   â”œâ”€â”€ app/             # Next.js app router
â”‚   â”œâ”€â”€ components/      # React components
â”‚   â””â”€â”€ lib/             # Utilities and types
â”œâ”€â”€ docker-compose.yml    # Local development infrastructure
â”œâ”€â”€ docker-compose.prod.yml  # Production deployment
â””â”€â”€ Dockerfile.*          # Service-specific Dockerfiles
```

## Performance

Current system handles:
- **1,000 vehicles** streaming at 10Hz
- **10,000 events/sec** sustained throughput
- **<5ms** p99 latency gRPC to Kafka
- **5s vehicle TTL** with 2s cleanup interval (prevents memory leaks)

## Monitoring

- **Dashboard**: http://localhost:3000
- **Prometheus Metrics**: http://localhost:2112/metrics
- **InfluxDB UI**: http://localhost:18086 (admin/voltstream2024)

## Development

### Rebuild protobuf:
```bash
protoc --go_out=. --go_opt=paths=source_relative \
  --go-grpc_out=. --go-grpc_opt=paths=source_relative \
  proto/telemetry.proto
```

### Run tests:
```bash
go test ./...
```

## License

MIT
